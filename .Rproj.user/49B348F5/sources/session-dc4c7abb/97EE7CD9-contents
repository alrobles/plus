#' plus model helper function
#'
#' @param x A set of independent numeric variables.
#' @param y A binary dependent variable
#' @param Sample_use_time Number of use time
#' @param l.rate learning rate
#' @param qq quantile threshold
#'
#' @return and object of the class plus
#' @export
#'
#' @examples
#' x = matrix(rnorm(1000 * 5), 1000, 5)
#' y = ifelse(rnorm(1000) > 0, 1, 0)
#' plus(x, y)
plus <- function(x, y, Sample_use_time = 30, l.rate = 1, qq = 0.1){
  train.X = x
  Label.obs = y
  pred.y0 = y
  
  this.call <- match.call()
  
  N <-  dim(train_data)[1]
  Label <- Label.obs
  valid.id <-  which(pred.y0 == 1)
  
  delta.p <-  array(Inf, N)
  PP <-  NULL
  invalid.id <-  seq(N)[-valid.id]
  prob_choosen <-  rep(1, length(invalid.id))
  names(prob_choosen) <-  invalid.id
  change_propor <-  c(0,0,0,0,0)
  
  
  for ( i in 1:10000 ) {
    # Randomly select the same amount of subjects to train with valid samples
    sample.id <-  sample(invalid.id, length(valid.id), replace = TRUE, prob = prob_choosen)
    sample.id <-  unique(sample.id)
    #Used_time controls how many time each sample are selected
    prob_choosen[as.character(sample.id)] <- prob_choosen[as.character(sample.id)]-(1/Sample_use_time)
    
    # train cv PLR model and do prediction
    fit.pi <- glmnet::cv.glmnet(train.X[c(valid.id, sample.id),], Label.obs[c(valid.id, sample.id)], family = "binomial")
    pred.y = stats::predict(object = fit.pi, newx = train.X, s = "lambda.min", type = 'response')
    #valid id in Label is true positive
    cutoff = stats::quantile(pred.y[valid.id], qq)
    
    # rescale
    map.pred.y = pred.y - cutoff
    map.pred.y[map.pred.y > 0] = map.pred.y[map.pred.y > 0]/max(map.pred.y[map.pred.y > 0])
    map.pred.y[map.pred.y < 0] = map.pred.y[map.pred.y < 0]/abs(min(map.pred.y[map.pred.y<0]))
    pred.y = 1/(1 + exp( -10*( map.pred.y )))
    
    # record something
    delta.p[sample.id] <-  pred.y[sample.id] - pred.y0[sample.id]
    
    # if there need learning rate: l.rate controls change rate from old to new
    pred.y0[sample.id] <-  pred.y[sample.id]*l.rate + (1 - l.rate)*pred.y0[sample.id]
    
    # shuffle:only change label of sample.id
    Label.sample.id.old <- Label.obs[sample.id]
    Label.obs[sample.id] <- stats::rbinom(length(sample.id), 1, pred.y0[sample.id])
    Label.sample.id.new <- Label.obs[sample.id]
    
    prob_choosen[which(prob_choosen<=0)] = 0
    #stop criteria 1: if 90% of prob_choosen<=0.01 stop
    if(sum(prob_choosen <= 0.01) > ( 0.9 * length(prob_choosen))){
      break
    }
    #stop criteria 2: convergency
    change_propor <- c(change_propor,
                       sum(Label.sample.id.old == Label.sample.id.new)/length(sample.id))
    if(mean(change_propor[(i + 1):(i + 5)]) > 0.9)
    {
      break
    }
  }
  
  # overall model, use all data which is given accurate labels from previous steps
  fit.pi <-  glmnet::cv.glmnet(train.X, Label.obs, family = "binomial")
  predicted_y <-  stats::predict(fit.pi, newx = train.X, s = "lambda.min", type = 'response')
  cutoff <-  stats::quantile(pred.y[valid.id], qq)
  predicted_coefficients <- glmnet::coef.glmnet(fit.pi, s = "lambda.min")
  
  
  plus_model <- new_plus(
    fit_plus = fit.pi,
    pred_y = predicted_y,
    cutoff = cutoff,
    predicted_coefficients = predicted_coefficients,
    call = this.call
  )

  return( validate_plus(plus_model) )
}
