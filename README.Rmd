---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# plus



<!--        _            -->
<!--  _ __ | |_   _ ___  -->
<!-- | '_ \| | | | / __| -->
<!-- | |_) | | |_| \__ \ -->
<!-- | .__/|_|\__,_|___/ -->
<!-- |_|                 -->


<!-- badges: start -->
<!-- badges: end -->

Positive and unlabeled Learning from Unbalanced cases and Sparse structures (PLUS)

## Installation

You can install the development version of plus from [GitHub](https://github.com/alrobles/PLUS) with:

``` r
# install.packages("devtools")
devtools::install_github("alrobles/plus")
```

The goal of plus is implement the Positive and unlabeled Learning from Unbalanced cases and Sparse structures (PLUS) algorithm, originally published in:
[PLoS](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1009956)
## Example

The use of plus is very simple:

```{r example, warning=FALSE}
library(plus)
data(binexample)
x = binexample$x
y = binexample$y
plus(x, y)
```

You can predict new data:

```{r predict, warning=FALSE}
data(binexample)
x = binexample$x
y = binexample$y
train <- sample(seq(length(y)), 85, replace = FALSE)
x_train <- x[train, ]
x_test  <- x[-train, ]
y_train <- y[train]
y_test  <- y[-train]
fit <- plus(x_train, y_train)
predict(fit, newx = x_test)
```

Additionally you can get evaluation performance metrics for the plus models

```{r roc, echo = FALSE, warning=FALSE}
#only Area under ROC curve
data(binexample)
x = binexample$x
y = binexample$y
train <- sample(seq(length(y)), 75, replace = FALSE)
x_train <- x[train, ]
x_test  <- x[-train, ]
y_train <- y[train]
y_test  <- y[-train]
fit <- plus(x_train, y_train)

#Get the AUC
get_auc(fit, x_test, y_test)


#get different performance metrics
assess(fit, newx = x_test, newy = y_test)
```

The plus algorithm can be applied in different datasets
